{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd99013d-d0f3-4e43-b529-6665c043906b",
   "metadata": {},
   "source": [
    "# Training Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326576e-f888-4f64-ba5e-aa31f1c78a5a",
   "metadata": {},
   "source": [
    "`Check table of initializers for each activation functions in the book (table 11-1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc20031-d1a3-4782-9aa3-aeb7c894cd75",
   "metadata": {},
   "source": [
    "A good initialization strategy for ReLU activation funcition is He initialization so as to alleviate the exploding/vanishing gradient problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4105112-a4be-4241-bf75-75032eb07fbb",
   "metadata": {},
   "source": [
    "\"By default, Keras uses Glorot initialization with a uniform distribution. When you create a layer, you can switch to He initialization by setting kernel_initializer=\"he_uniform\" or kernel_initializer=\"he_normal\" like this:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e8835c-9e86-4388-bc44-120faff9b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dense = tf.keras.layers.Dense(50, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92be56c5-14c0-4695-b974-03f914914123",
   "metadata": {},
   "source": [
    "\"Alternatively, you can obtain any of the initializations listed in table 11-1 and more using the VarianceScaling initializer. For example, if you want He initialization with a uniform distribution and based on fan_avg (rather than fan_in), you can use the following code:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19af5bf-d5dd-4d60-8d3e-21ccdf422478",
   "metadata": {},
   "outputs": [],
   "source": [
    "he_avg_init = tf.keras.initializers.VarianceScaling(scale=2., mode=\"fan_avg\",\n",
    "                                                    distribution=\"uniform\")\n",
    "dense = tf.keras.layers.Dense(50, activation=\"sigmoid\", kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db75d22a-795a-4c65-8ac2-caca27a0770c",
   "metadata": {},
   "source": [
    "Better activation functions reduce instability of gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb66e413-c844-4178-a153-e03f3e1f39fa",
   "metadata": {},
   "source": [
    "## Better activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae0156-7383-4214-9c96-10c20f672d6d",
   "metadata": {},
   "source": [
    "### Leaky ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d697c945-d766-40f1-a9c5-7f95a18ae399",
   "metadata": {},
   "source": [
    "\"Keras includes the classes LeakyReLU and PReLU in the tf.keras.layers package. Just like for other ReLU variants, you should use He initialization with these. For example:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4aeadae-0d95-406a-a573-1ec7d92eee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_relu = tf.keras.layers.LeakyReLU(negative_slope=0.2) # defaults to alpha=0.3, alpha changed to \"negative_slope\"\n",
    "dense = tf.keras.layers.Dense(50, activation=leaky_relu, kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756bf168-a187-4196-a96d-2dc588c47dfa",
   "metadata": {},
   "source": [
    "We can also use LeakyReLU as a separate layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d908c98-3757-42a2-8df6-7c006d45aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=[10]),\n",
    "    tf.keras.layers.Dense(50, kernel_initializer=\"he_normal\"), # no activation\n",
    "    tf.keras.layers.LeakyReLU(negative_slope=0.2), # activation as a separate layer\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92637c0-90c7-4872-9415-81d32c5746a8",
   "metadata": {},
   "source": [
    "### PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c975f9-585f-4bf6-bf45-20afe7b989f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_prelu = tf.keras.layers.PReLU()\n",
    "dense = tf.keras.layers.Dense(50, activation=leaky_prelu, kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123d72bf-d211-407a-9666-c72daa368ad3",
   "metadata": {},
   "source": [
    "Smooth variants of the ReLU activation function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c41bc-efcf-45fc-9fdf-695746a4eef2",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "909c37ac-db90-4727-bc41-ac091c0d6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(50, activation=\"elu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec575b4-798c-40fc-8670-9dbdd25e2fa4",
   "metadata": {},
   "source": [
    "### SELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe5dd3c-e852-443a-a23f-be9578c80175",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(50, activation=\"selu\", kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898930cc-b007-49bb-80f3-722ea50b4659",
   "metadata": {},
   "source": [
    "### GELU, Swish, Mish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8d18bee-30d6-46d1-b50d-8d9317b2ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(50, activation=\"gelu\", kernel_initializer=\"he_normal\")\n",
    "dense = tf.keras.layers.Dense(50, activation=\"swish\", kernel_initializer=\"he_normal\") # Keras does not support generalized Swish\n",
    "# dense = tf.keras.layers.Dense(50, activation=\"mish\", kernel_initializer=\"he_normal\")  # Keras does not support mish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b5bd06-adc5-4f7a-bc23-2b32d7b2c35f",
   "metadata": {},
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5a58385-ee22-44c0-9caf-000f12f56115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │           \u001b[38;5;34m3,136\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │         \u001b[38;5;34m235,500\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │           \u001b[38;5;34m1,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m30,100\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │             \u001b[38;5;34m400\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,010\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">271,346</span> (1.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m271,346\u001b[0m (1.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,978</span> (1.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m268,978\u001b[0m (1.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> (9.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,368\u001b[0m (9.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=[28, 28]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b3db2-0a1c-452e-9fa1-d5e595714a32",
   "metadata": {},
   "source": [
    "Looking at parameters of the first BN layer. 2 are trainable (by backpropagation) and 2 are not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb1896bf-56ea-47cc-8c89-02034ae1f180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gamma', True),\n",
       " ('beta', True),\n",
       " ('moving_mean', False),\n",
       " ('moving_variance', False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4064f1-a801-437b-859e-93e4bb604d15",
   "metadata": {},
   "source": [
    "Adding BN layers before the activation functions this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e55dd97-9039-4787-b799-f7268951aa1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">235,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">30,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │         \u001b[38;5;34m235,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │           \u001b[38;5;34m1,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m30,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │             \u001b[38;5;34m400\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,010\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">267,810</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m267,810\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">267,010</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m267,010\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> (3.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m800\u001b[0m (3.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Removing bias on layers that come before BN since BN layers already has a bias term.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=[28, 28]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(\"relu\"),\n",
    "    tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c8b02f-2263-4f3a-818b-dc23065b7758",
   "metadata": {},
   "source": [
    "## Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "191e7e4d-278e-4342-bca0-96afd283c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally used in RNN to mitigate exploding gradients\n",
    "optimizer = tf.keras.optimizers.SGD(clipvalue=1.0)\n",
    "optimizer = tf.keras.optimizers.SGD(clipnorm=1.0) # if you want to preserve orientation of gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efb04e2-638c-42af-9613-3c095b926b23",
   "metadata": {},
   "source": [
    "## Transfer Learning with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fdb555-ba5d-4311-a7a3-38e510cca63b",
   "metadata": {},
   "source": [
    "Use transfer learning for learning the `fashion` mnist dataset. I will pretend I only have 100 instances of each class on the training set. I will train an MLP to see its performance on 1000 samples, then I will use transfer learning to compare performance. The MLP whose layers I will transfer was trained on MNIST dataset with 50k samples on the training set and 98% accuracy on the validation set (10k samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5376f1c-0e34-4305-b2f9-054dfa6a1f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ianvi\\env\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3135d30d-30bb-4e99-9ac7-91573993afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc51894a-34e7-4a80-a6a2-ac997e38ea10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], shape=(10000,), dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96266fef-6e43-4a44-89de-75874abda482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_full.shape)\n",
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4663fee3-3b11-4b30-936e-c75b66169b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1k = np.zeros(shape=(1000, 28, 28), dtype=np.uint8)\n",
    "y_train_1k = np.zeros(shape=(1000,), dtype=np.uint8)\n",
    "\n",
    "# get 100 instances from each class\n",
    "for i in range(10):\n",
    "    first_index = i*100\n",
    "    indices = y_train_full == i\n",
    "    x_100 = X_train_full[indices][:100]\n",
    "    y_100 = y_train_full[indices][:100]\n",
    "    X_train_1k[first_index : first_index + 100] = x_100\n",
    "    y_train_1k[first_index : first_index + 100] = y_100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "224211f0-e239-4818-9c07-96051d1d2147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_1k[90:110] # checking if it is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee764589-fc43-44d9-a736-b4ed1f6a60b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   1,   0,   0,   0,  49, 136, 219, 216, 228, 236,\n",
       "       255, 255, 255, 255, 217, 215, 254, 231, 160,  45,   0,   0,   0,\n",
       "         0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1k[0][1] # checking if it has non-zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40f9a927-9569-4862-ab0e-49d9ab0ee120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([978, 933, 859, 916, 127, 608, 856, 260, 147, 810])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_shuffled = np.random.default_rng(seed=42).permutation(y_train_1k.shape[0])\n",
    "indices_shuffled[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60b29c66-a3c7-4126-88e8-ef3f3a60fb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9, 8, 9, 1, 6, 8, 2, 1, 8], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle dataset\n",
    "X_train_1k = X_train_1k[indices_shuffled]\n",
    "y_train_1k = y_train_1k[indices_shuffled]\n",
    "y_train_1k[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cab5547-8889-4490-9be6-4f68a67ccf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 28, 28) (800,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_1k[:800]\n",
    "y_train = y_train_1k[:800]\n",
    "X_valid = X_train_1k[800:]\n",
    "y_valid = y_train_1k[800:]\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "131797a3-d9c6-4091-964d-6754a8b0e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=[28, 28]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(480, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(480, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(480, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(480, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(480, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_B.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=[\"accuracy\"]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df2ccbe2-24ee-4f6e-9346-0b11a79de5ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.4275 - loss: 91.1915 - val_accuracy: 0.5350 - val_loss: 16.5927\n",
      "Epoch 2/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6850 - loss: 9.3166 - val_accuracy: 0.6500 - val_loss: 8.2295\n",
      "Epoch 3/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7337 - loss: 5.3916 - val_accuracy: 0.6250 - val_loss: 6.6847\n",
      "Epoch 4/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7862 - loss: 3.0369 - val_accuracy: 0.7550 - val_loss: 4.3091\n",
      "Epoch 5/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8087 - loss: 2.3798 - val_accuracy: 0.7250 - val_loss: 4.3688\n",
      "Epoch 6/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8425 - loss: 1.8060 - val_accuracy: 0.7550 - val_loss: 2.7328\n",
      "Epoch 7/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8525 - loss: 1.7168 - val_accuracy: 0.6950 - val_loss: 4.5949\n",
      "Epoch 8/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8575 - loss: 1.2473 - val_accuracy: 0.7450 - val_loss: 2.7404\n",
      "Epoch 9/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8913 - loss: 0.7153 - val_accuracy: 0.7550 - val_loss: 3.3275\n",
      "Epoch 10/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9025 - loss: 0.8525 - val_accuracy: 0.7150 - val_loss: 4.5281\n",
      "Epoch 11/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8725 - loss: 1.0651 - val_accuracy: 0.7450 - val_loss: 2.9031\n",
      "Epoch 12/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8750 - loss: 0.8269 - val_accuracy: 0.7400 - val_loss: 2.4137\n",
      "Epoch 13/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9187 - loss: 0.5013 - val_accuracy: 0.7700 - val_loss: 1.9568\n",
      "Epoch 14/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9325 - loss: 0.3292 - val_accuracy: 0.7400 - val_loss: 2.6668\n",
      "Epoch 15/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9262 - loss: 0.3929 - val_accuracy: 0.7400 - val_loss: 2.1409\n",
      "Epoch 16/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9300 - loss: 0.4100 - val_accuracy: 0.7300 - val_loss: 2.9670\n",
      "Epoch 17/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9300 - loss: 0.4506 - val_accuracy: 0.7500 - val_loss: 2.7419\n",
      "Epoch 18/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9400 - loss: 0.3576 - val_accuracy: 0.7500 - val_loss: 2.5679\n",
      "Epoch 19/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9187 - loss: 0.5005 - val_accuracy: 0.8050 - val_loss: 2.4993\n",
      "Epoch 20/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9237 - loss: 0.4568 - val_accuracy: 0.7600 - val_loss: 3.0182\n",
      "Epoch 21/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9187 - loss: 0.6216 - val_accuracy: 0.7400 - val_loss: 2.8053\n",
      "Epoch 22/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9038 - loss: 0.8513 - val_accuracy: 0.7500 - val_loss: 2.4410\n",
      "Epoch 23/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8750 - loss: 0.8641 - val_accuracy: 0.7550 - val_loss: 2.6282\n",
      "Epoch 24/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9025 - loss: 0.5714 - val_accuracy: 0.7300 - val_loss: 2.4644\n",
      "Epoch 25/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9237 - loss: 0.4282 - val_accuracy: 0.7650 - val_loss: 2.1717\n",
      "Epoch 26/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9250 - loss: 0.4980 - val_accuracy: 0.7700 - val_loss: 2.0970\n",
      "Epoch 27/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9175 - loss: 0.5239 - val_accuracy: 0.7550 - val_loss: 2.7571\n",
      "Epoch 28/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8975 - loss: 0.4951 - val_accuracy: 0.7750 - val_loss: 2.2533\n",
      "Epoch 29/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9413 - loss: 0.2992 - val_accuracy: 0.7650 - val_loss: 2.2019\n",
      "Epoch 30/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9475 - loss: 0.4262 - val_accuracy: 0.8100 - val_loss: 1.9160\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train, y_train,\n",
    "                      validation_data=(X_valid, y_valid),\n",
    "                     epochs=30,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebbb2545-1e26-4308-8a3b-4f1c3cd1e525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8100 - loss: 1.9160 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9159855842590332, 0.8100000023841858]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3539349-066a-4b77-babb-0a679eb6045b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7272 - loss: 3.4780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.477980852127075, 0.7271999716758728]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e749aad4-8514-4aa4-bd65-621ccd7ea4a7",
   "metadata": {},
   "source": [
    "Accuracy of model B on test set is 73%. Now, with transfer learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "893514fa-707e-462f-8eee-d7197d52208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model A which was trained on the mnist dataset (on ch10 notebook)\n",
    "model_A = tf.keras.models.clone_model(model_B)\n",
    "\n",
    "# Compiling would be needed if the model were created from scratch\n",
    "# model_A.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00021647994826791666),\n",
    "#                 loss=\"sparse_categorical_crossentropy\",\n",
    "#                 metrics=[\"accuracy\"]\n",
    "#                )\n",
    "\n",
    "model_A.load_weights(\"../ch10/checkpoints_q10_mnist.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e4731dd-277a-4413-9102-071add51bbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9817 - loss: 0.1447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14471349120140076, 0.9817000031471252]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if model was loaded correctly\n",
    "(X_train_full_mnist, y_train_full_mnist), (X_test_mnist, y_test_mnist) = tf.keras.datasets.mnist.load_data()\n",
    "model_A.evaluate(X_test_mnist, y_test_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7355437d-d9ec-40d1-98e3-ee796006a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloning model so model A is not affected by training new model\n",
    "model_A_clone = tf.keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38d85bd8-b53b-46b8-9016-3aa201855609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying bottom 2 hidden layers ( + flatten layer)\n",
    "model_B_on_A = tf.keras.Sequential(model_A_clone.layers[:3])\n",
    "model_B_on_A.add(tf.keras.layers.Dense(480, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model_B_on_A.add(tf.keras.layers.Dense(480, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model_B_on_A.add(tf.keras.layers.Dense(480, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model_B_on_A.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ffe51bc-8548-4d90-b0c1-6d26f55d9964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze bottom 2 layers\n",
    "for layer in model_B_on_A.layers[:3]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Always compile after freezing/unfreezing layers\n",
    "model_B_on_A.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=[\"accuracy\"]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48b761d3-5bea-464f-9669-1bfcb06fd068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5400 - loss: 30.8260 - val_accuracy: 0.6350 - val_loss: 8.1867\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7862 - loss: 3.5184 - val_accuracy: 0.7000 - val_loss: 3.9160\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8500 - loss: 1.7014 - val_accuracy: 0.7350 - val_loss: 3.5219\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9050 - loss: 0.9528 - val_accuracy: 0.7200 - val_loss: 3.4333\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8938 - loss: 1.6955 - val_accuracy: 0.6950 - val_loss: 5.5155\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9300 - loss: 0.8062 - val_accuracy: 0.7250 - val_loss: 2.1537\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9613 - loss: 0.2362 - val_accuracy: 0.6600 - val_loss: 3.8070\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9688 - loss: 0.3525 - val_accuracy: 0.7000 - val_loss: 3.0789\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9663 - loss: 0.2903 - val_accuracy: 0.7200 - val_loss: 3.4820\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9388 - loss: 0.7401 - val_accuracy: 0.7400 - val_loss: 3.2164\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cccc3fa-c400-4637-8bf9-ec84c050049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze bottom 2 layers to fine-tune\n",
    "for layer in model_B_on_A.layers[:3]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Always compile after freezing/unfreezing layers\n",
    "model_B_on_A.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=[\"accuracy\"]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cee27ad-00a3-4b71-91ca-fbf5fce2cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9675 - loss: 0.1538 - val_accuracy: 0.7300 - val_loss: 2.2358\n",
      "Epoch 2/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9812 - loss: 0.1068 - val_accuracy: 0.7500 - val_loss: 2.5014\n",
      "Epoch 3/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9837 - loss: 0.0566 - val_accuracy: 0.7300 - val_loss: 2.7308\n",
      "Epoch 4/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9937 - loss: 0.0354 - val_accuracy: 0.7750 - val_loss: 2.0907\n",
      "Epoch 5/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9937 - loss: 0.0280 - val_accuracy: 0.7700 - val_loss: 2.6440\n",
      "Epoch 6/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9962 - loss: 0.0367 - val_accuracy: 0.7950 - val_loss: 2.2305\n",
      "Epoch 7/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9987 - loss: 0.0178 - val_accuracy: 0.8000 - val_loss: 2.2366\n",
      "Epoch 8/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 6.8848e-04 - val_accuracy: 0.8050 - val_loss: 2.0405\n",
      "Epoch 9/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 1.5640e-04 - val_accuracy: 0.8000 - val_loss: 2.0263\n",
      "Epoch 10/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.4244e-05 - val_accuracy: 0.8000 - val_loss: 2.0241\n",
      "Epoch 11/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 6.5109e-05 - val_accuracy: 0.8050 - val_loss: 2.0264\n",
      "Epoch 12/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 5.6142e-05 - val_accuracy: 0.8050 - val_loss: 2.0293\n",
      "Epoch 13/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 4.9144e-05 - val_accuracy: 0.8050 - val_loss: 2.0318\n",
      "Epoch 14/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 4.3853e-05 - val_accuracy: 0.8050 - val_loss: 2.0332\n",
      "Epoch 15/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.9477e-05 - val_accuracy: 0.8050 - val_loss: 2.0355\n",
      "Epoch 16/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.6505e-05 - val_accuracy: 0.8050 - val_loss: 2.0373\n",
      "Epoch 17/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 3.2954e-05 - val_accuracy: 0.8050 - val_loss: 2.0388\n",
      "Epoch 18/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 3.0256e-05 - val_accuracy: 0.8050 - val_loss: 2.0395\n",
      "Epoch 19/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.8187e-05 - val_accuracy: 0.8050 - val_loss: 2.0415\n",
      "Epoch 20/20\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 2.6184e-05 - val_accuracy: 0.8050 - val_loss: 2.0440\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a16fc244-86e4-49b8-aed1-344c23dfd446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7406 - loss: 3.6280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.62803053855896, 0.7405999898910522]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0542e1-fe16-4e64-b210-b9329457b3de",
   "metadata": {},
   "source": [
    "The loss increased and the accuracy decreased a bit. Transfer learning did not help much here probably because I should have used 1 hidden layer (because tasks are very different) or trained the NN with frozen layers for more epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bacc1d6-e473-42da-ab86-ac51102de311",
   "metadata": {},
   "source": [
    "The author says \"transfer learning does not work very well with small dense networks, presumably because small networks learn few patterns, and dense networks learn very specific patterns, which are unlikely to be useful in other tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bee6ce-ee20-4f9a-bb39-cf1d946bad59",
   "metadata": {},
   "source": [
    "##  Faster Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a544851c-468a-412e-8a7a-eea64a427666",
   "metadata": {},
   "source": [
    "Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0db94e7c-1d87-464e-b519-d74693a4c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e2517a-cde7-4af1-b337-3e9363093b7a",
   "metadata": {},
   "source": [
    "Nesterov Accelerated Gradient (NAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "276078ff-c0df-4b49-b570-53e3d99fb94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539b5bef-d4bb-4bf1-85d1-f99bc491b8a8",
   "metadata": {},
   "source": [
    "RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2213ff8-43ea-43ee-a27e-1558ce3cac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2c9633-e100-4275-a571-e51b473ff91e",
   "metadata": {},
   "source": [
    "Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c995f97e-279e-461b-972a-565b0e8e8429",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee490e-e766-4e32-aa97-8081a1194f3f",
   "metadata": {},
   "source": [
    "Adamax, Nadam, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "384cd425-6581-458b-b1f0-2a2bdb356004",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adamax(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=0.001, beta_1=0.9, beta_2=0.999, weight_decay=0.96)\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b312e-a93b-4ccf-8e0b-e30bf7712455",
   "metadata": {},
   "source": [
    "\"Combining l2 regularization with Adam often results in models that do not generalize well.\" Use adam with weight decay (adamW) instead.\n",
    "Sometimes, adaptive gradients (RMSProp, adam and its variations) do not generalize well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28332615-3c51-4125-9090-313c095e84c0",
   "metadata": {},
   "source": [
    "See table 11-2 for optimizers comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0687e51-ac8e-4a53-adc3-cabea81c65cb",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb3b47-11c0-4869-ab9e-038f5dcf763c",
   "metadata": {},
   "source": [
    "Exponential scheduling (or exponential decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1d74f41-99d3-4b3c-9755-42f9218228a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1 ** (epoch / 20)\n",
    "\n",
    "# if you do not want to hardcode function \n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 ** (epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c62126c-99eb-4c12-898a-83f6ffb29d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LearningRateScheduler callback\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "# Example\n",
    "# history = model.fit(X_train, y_train, epochs=10, callbacks=[lr_schedueler]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2b153-8371-423b-afc9-76e6cff64826",
   "metadata": {},
   "source": [
    "The scheudle function can optionally take the current learning rate as a second argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87557ba4-8b11-4d3d-a3e3-f1abaf5deb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1 ** (1 / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38a3ce0-6621-427f-8b42-3c0c096b23ea",
   "metadata": {},
   "source": [
    "`When saving a model, the epoch does not get saved! If training again after loading model the epoch will start at 0! To solve this, use a learning schedule function independent of epoch or use fit()'s initial_epoch parameter`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8347447-f0e2-4e49-941c-41f847cde92d",
   "metadata": {},
   "source": [
    "Piecewise constant scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df83b89f-2ddb-47d2-9add-77611e112d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001\n",
    "\n",
    "# Can create a more general function if I do not want to hardcode epoch thresholds just like previous section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedb380e-4729-4e55-82b5-8845bd4ae165",
   "metadata": {},
   "source": [
    "Performance scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ccd7ce0-f8fa-43df-90c9-24d4605678e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "# this multiplies learning rate by 0.5 if best validation loss does not improve for 5 consecutive epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f1a34e-d3a8-43c9-a05a-69e5a77ab062",
   "metadata": {},
   "source": [
    "Alternative to implementing learning rate scheduling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9167062-cd06-4fcb-b516-01731fda7e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 20\n",
    "n_steps = n_epochs * np.ceil(len(X_train) / batch_size)\n",
    "scheduled_learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01, decay_steps=n_steps, decay_rate=0.1)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=scheduled_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c01ae-c976-427c-8120-ef89815b6cf5",
   "metadata": {},
   "source": [
    "The code above \"is nice and simple, plus when you save the model, the learning rate and its schedule (including its state) get saved as well.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e44a4f6-d3ba-415c-a393-a50cc4d28c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement power scheduling\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=10_000,\n",
    "    decay_rate=1.0,\n",
    "    staircase=False\n",
    ")\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adbeea1-4fd2-490d-a6c3-290c24f8140c",
   "metadata": {},
   "source": [
    "##  Avoid overfitting through regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5205ea-da8a-48bc-924f-b9124b8659cd",
   "metadata": {},
   "source": [
    "### $l_1$ and $l_2$ regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35229ff9-38a9-434b-9665-e02ee8f0c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l2\n",
    "layer = tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(0.01)\n",
    "                             )\n",
    "# l1\n",
    "layer = tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=tf.keras.regularizers.l1(0.01)\n",
    "                             )\n",
    "# l1 and l2\n",
    "layer = tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.01, l2=0.01)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76245c31-3e8a-4803-8ead-b8dc28ff799f",
   "metadata": {},
   "source": [
    "You tipically want to apply the same activation function, initializer, and regularizer in all hidden layers. To avoid too much repetition, you can use loops or Python's functools.partial() function, which lets you creat a thin wrapper for any callable, with some default argument values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecdd2074-a0b7-4d64-bf88-a100ad46f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(tf.keras.layers.Dense,\n",
    "                 activation=\"relu\",\n",
    "                 kernel_initializer=\"he_normal\",\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=[28, 28]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fed6a1-9f82-4d05-a649-f81925961eb8",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "461cb102-0123-4739-a1eb-fa903d0c38af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.2450 - loss: 91.0348 - val_accuracy: 0.4950 - val_loss: 10.1590\n",
      "Epoch 2/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3225 - loss: 22.7316 - val_accuracy: 0.3300 - val_loss: 5.0413\n",
      "Epoch 3/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3125 - loss: 6.8452 - val_accuracy: 0.3100 - val_loss: 3.5483\n",
      "Epoch 4/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3088 - loss: 4.3433 - val_accuracy: 0.2650 - val_loss: 2.9787\n",
      "Epoch 5/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2837 - loss: 3.1877 - val_accuracy: 0.2700 - val_loss: 2.4408\n",
      "Epoch 6/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2937 - loss: 2.6116 - val_accuracy: 0.2250 - val_loss: 2.4072\n",
      "Epoch 7/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2763 - loss: 2.5618 - val_accuracy: 0.2200 - val_loss: 2.2906\n",
      "Epoch 8/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2812 - loss: 2.3946 - val_accuracy: 0.2500 - val_loss: 2.1411\n",
      "Epoch 9/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2700 - loss: 2.3380 - val_accuracy: 0.2400 - val_loss: 2.1346\n",
      "Epoch 10/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2663 - loss: 2.2718 - val_accuracy: 0.2350 - val_loss: 2.0733\n",
      "Epoch 11/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3175 - loss: 2.1852 - val_accuracy: 0.2600 - val_loss: 2.1857\n",
      "Epoch 12/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3325 - loss: 2.3551 - val_accuracy: 0.2750 - val_loss: 2.1429\n",
      "Epoch 13/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3250 - loss: 2.1358 - val_accuracy: 0.2500 - val_loss: 1.9665\n",
      "Epoch 14/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2837 - loss: 2.1072 - val_accuracy: 0.2350 - val_loss: 2.0451\n",
      "Epoch 15/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2975 - loss: 2.0209 - val_accuracy: 0.2450 - val_loss: 2.0714\n",
      "Epoch 16/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3137 - loss: 1.9823 - val_accuracy: 0.2600 - val_loss: 2.2752\n",
      "Epoch 17/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3288 - loss: 2.0210 - val_accuracy: 0.2750 - val_loss: 2.0778\n",
      "Epoch 18/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3625 - loss: 1.9199 - val_accuracy: 0.2950 - val_loss: 2.2673\n",
      "Epoch 19/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3550 - loss: 1.9375 - val_accuracy: 0.3100 - val_loss: 2.2525\n",
      "Epoch 20/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3500 - loss: 1.9170 - val_accuracy: 0.2700 - val_loss: 2.1287\n",
      "Epoch 21/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3325 - loss: 2.0160 - val_accuracy: 0.2750 - val_loss: 1.9078\n",
      "Epoch 22/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2912 - loss: 2.0911 - val_accuracy: 0.2450 - val_loss: 1.9754\n",
      "Epoch 23/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3212 - loss: 1.8837 - val_accuracy: 0.2650 - val_loss: 1.9771\n",
      "Epoch 24/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3225 - loss: 1.9775 - val_accuracy: 0.2500 - val_loss: 2.2583\n",
      "Epoch 25/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3225 - loss: 1.9271 - val_accuracy: 0.2650 - val_loss: 1.8770\n",
      "Epoch 26/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3288 - loss: 1.8756 - val_accuracy: 0.2550 - val_loss: 1.9034\n",
      "Epoch 27/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3200 - loss: 1.8528 - val_accuracy: 0.2550 - val_loss: 1.9148\n",
      "Epoch 28/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3237 - loss: 1.9140 - val_accuracy: 0.2550 - val_loss: 1.8970\n",
      "Epoch 29/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3462 - loss: 1.8169 - val_accuracy: 0.3050 - val_loss: 2.0831\n",
      "Epoch 30/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3613 - loss: 1.9049 - val_accuracy: 0.2850 - val_loss: 1.8107\n",
      "Epoch 31/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3650 - loss: 1.7777 - val_accuracy: 0.3200 - val_loss: 1.7677\n",
      "Epoch 32/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3738 - loss: 1.8230 - val_accuracy: 0.2900 - val_loss: 1.8526\n",
      "Epoch 33/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3500 - loss: 1.7588 - val_accuracy: 0.2800 - val_loss: 1.8369\n",
      "Epoch 34/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3562 - loss: 1.8674 - val_accuracy: 0.2850 - val_loss: 1.7881\n",
      "Epoch 35/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3663 - loss: 1.7262 - val_accuracy: 0.2900 - val_loss: 1.8714\n",
      "Epoch 36/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3525 - loss: 1.8506 - val_accuracy: 0.2850 - val_loss: 1.8030\n",
      "Epoch 37/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3562 - loss: 1.7839 - val_accuracy: 0.3000 - val_loss: 1.9684\n",
      "Epoch 38/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3675 - loss: 1.7533 - val_accuracy: 0.2800 - val_loss: 1.9142\n",
      "Epoch 39/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3537 - loss: 1.8068 - val_accuracy: 0.2850 - val_loss: 1.8683\n",
      "Epoch 40/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3562 - loss: 1.8185 - val_accuracy: 0.2650 - val_loss: 2.0224\n",
      "Epoch 41/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3487 - loss: 1.9375 - val_accuracy: 0.2650 - val_loss: 2.0248\n",
      "Epoch 42/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3675 - loss: 1.7282 - val_accuracy: 0.2450 - val_loss: 2.0702\n",
      "Epoch 43/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3512 - loss: 1.7676 - val_accuracy: 0.2950 - val_loss: 1.8001\n",
      "Epoch 44/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3713 - loss: 1.7050 - val_accuracy: 0.2800 - val_loss: 1.9462\n",
      "Epoch 45/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3537 - loss: 1.7390 - val_accuracy: 0.3000 - val_loss: 2.0704\n",
      "Epoch 46/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3700 - loss: 1.9021 - val_accuracy: 0.2550 - val_loss: 1.8832\n",
      "Epoch 47/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3587 - loss: 1.8053 - val_accuracy: 0.2700 - val_loss: 2.0595\n",
      "Epoch 48/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3600 - loss: 1.9014 - val_accuracy: 0.3200 - val_loss: 2.2603\n",
      "Epoch 49/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3700 - loss: 1.8408 - val_accuracy: 0.3150 - val_loss: 1.8443\n",
      "Epoch 50/50\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3400 - loss: 1.7648 - val_accuracy: 0.3000 - val_loss: 1.8981\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=[28, 28]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"]\n",
    "             )\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9355b358-03c5-4a06-9010-81e82c4017f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3000 - loss: 1.8981 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8980798721313477, 0.30000001192092896]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0402beea-c552-49cd-a9fd-bb034e59f409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3563 - loss: 1.9297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9297410249710083, 0.3562999963760376]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca709caf-2bc2-4630-8652-f382347be387",
   "metadata": {},
   "source": [
    "\"Since dropout is only active during training, comparing the training loss and the validation loss can be misleading. In particular, a model may be overfitting the training set and yet have a similar training and validation losses. So, make sure to evaluate the training loss without dropout (e.g. after training)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af1b092-3f1f-4503-8557-34b4736d479e",
   "metadata": {},
   "source": [
    "### Monte Carlo (MC) Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d275a4f5-effe-4d01-a1f4-9ce56e4f3e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_probas = np.stack([model(X_test, training=True) \n",
    "                     for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a8983ac-ae40-4675-ad4b-7cebbb44d8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.032, 0.034, 0.029, 0.013, 0.05 , 0.081, 0.031, 0.121, 0.062,\n",
       "        0.547]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when dropout is turned off\n",
    "model.predict(X_test[:1]).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8fd5841-b321-4ab3-beb6-e67c108e7791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.084, 0.034, 0.089, 0.066, 0.085, 0.045, 0.081, 0.072, 0.08 ,\n",
       "       0.364], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with MC dropout prediction\n",
    "y_proba[0].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f161065-588e-4000-80c1-9c8ca05e31fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.061, 0.023, 0.063, 0.05 , 0.059, 0.033, 0.059, 0.077, 0.054,\n",
       "       0.392], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard deviation\n",
    "y_std = y_probas.std(axis=0)\n",
    "y_std[0].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54bae2cc-08a7-4378-b25a-9d1b13481492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4573\n"
     ]
    }
   ],
   "source": [
    "y_pred = y_proba.argmax(axis=1)\n",
    "accuracy = (y_pred == y_test).sum() / len(y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd5dddf-dfec-47b6-bd9e-a00be24d19c9",
   "metadata": {},
   "source": [
    "Accuracy improved from 37% to 43.8%!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e040e6-f6b9-4592-8756-0a9ce14c4a4d",
   "metadata": {},
   "source": [
    "\"If  your model contains other layers that behave in a special way during training (such as BatchNormalization), then you should not force training model like we just did. Instad, you should replace the Dropout layers with the following MCDropout class:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ecd01d3-c8c9-4472-aeec-6f26242a5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(tf.keras.layers.Dropout):\n",
    "    def call(self, inputs, training=False):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b166312b-2660-4d99-9dcb-f4772e0571b0",
   "metadata": {},
   "source": [
    "###  Max-Norm Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c620fe5-d38a-4743-9460-f08b36092607",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(\n",
    "    100, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
    "    kernel_constraint=tf.keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d64b760-551f-461c-b519-784316d3a4db",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23686976-6bbd-44e9-a3d2-eddec588e067",
   "metadata": {},
   "source": [
    "1. To alleviate the unstable gradient problem.\n",
    "2. It is not ok, because all neurons in a layer would have the same gradients and the entire layer would be equivalent to a single neuron multiplied by number of neurons in the layer. This would not generalize well as it would feel like there is a single neuron per hidden layer.\n",
    "3.  I think, if all weights are initialized correctly, it is ok.\n",
    "4.  Leaky Relu or Relu for faster (or just shallow) neural nets. SELU for deep dense nets. Swish, mish, GELU for any deep nets.\n",
    "5.  Momentum's peak \"speed\" becomes much larger. However, it also takes longer to slow down.\n",
    "6.  Use strong $l_1$ regularization, TF-mot package, and get rid of tiny weights.\n",
    "7.  Dropout does slow down training because it is as if we are training a different model everytime. It does not slow down inference. MC dropout does slow down inferece because it makes the model predict on the same instance multiple times. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb6856-f447-47f9-891f-a1e77a682067",
   "metadata": {},
   "source": [
    "8. Coding question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9de9ad67-3df2-4743-9b4c-5122821e0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_nn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(32, 32)),\n",
    "    tf.keras.layers.Flatten()\n",
    "])\n",
    "hidden = partial(tf.keras.layers.Dense,\n",
    "                 units=100,\n",
    "                 activation=\"swish\",\n",
    "                 kernel_initializer=\"he_normal\"\n",
    "                )\n",
    "\n",
    "for _ in range(20):\n",
    "    deep_nn.add(hidden())\n",
    "\n",
    "deep_nn.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cde915b6-e0ae-422e-9c4b-9c0c7f3f86b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deep_nn.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f9575d2-d163-4ccf-b243-d8b5ff98f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class exponential_lr(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.losses = []\n",
    "        self.rates = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        lr = self.model.optimizer.learning_rate.numpy() * self.factor\n",
    "        self.model.optimizer.learning_rate = lr\n",
    "        self.rates.append(lr)\n",
    "        self.losses.append(logs[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ca870e0-adaf-42a3-9d9e-94e645ba7b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(model, X_train, y_train, lr0=1e-5, factor=1.005):\n",
    "    model = tf.keras.models.clone_model(model)\n",
    "    expo_lr = exponential_lr(factor=factor)\n",
    "    optimizer = tf.keras.optimizers.Nadam(learning_rate=lr0)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=1,\n",
    "                        validation_split=0.2,\n",
    "                        callbacks=[expo_lr]\n",
    "                       )\n",
    "\n",
    "    losses = expo_lr.losses\n",
    "    rates = expo_lr.rates\n",
    "\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale(\"log\")\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"Learning rate (log)\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b2b45cb-5659-4c1f-9188-cdc669fce70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ianvi\\env\\Lib\\site-packages\\keras\\src\\datasets\\cifar.py:18: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  d = cPickle.load(f, encoding=\"bytes\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c343612-1d50-429e-af44-1c32df262cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], shape=(50000, 1), dtype=uint8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
