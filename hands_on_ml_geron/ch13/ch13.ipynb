{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e4ed82-3bf5-47c4-bce0-2592429eb480",
   "metadata": {},
   "source": [
    "# **Chapter 13 â€“ Loading and Preprocessing Data with TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78770d3-2b05-4fd7-b4f8-43f5ab8ea645",
   "metadata": {},
   "source": [
    "# The tf.data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20020016-d802-4cb4-9f78-b1a371865174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e131e8-2179-43f0-aa39-1ce9b94aed63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(10) # any data tensor\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd9cbe0b-44b2-4ba8-bdea-baa5dad5011f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_RangeDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or \n",
    "tf.data.Dataset.range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4432a1e-4a7b-4cb5-88d0-05fbbbc4875a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# can iterate\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad97793-95c2-4412-b480-c96ecdb90845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=4>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=7>}\n",
      "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=5>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=8>}\n",
      "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=6>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=9>}\n"
     ]
    }
   ],
   "source": [
    "X_nested = {\"a\": ([1, 2, 3], [4, 5, 6]), \"b\": [7, 8, 9]}\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_nested)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb5f51e-1b13-46de-a4ad-cb0d0cfcb4cf",
   "metadata": {},
   "source": [
    "## Chaining Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c901668-d264-4964-865b-ec0fea86654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
    "dataset = dataset.repeat(3).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "881009a2-7634-4088-82c9-c03ef8ad0bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
      "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# tranforming items by calling map()\n",
    "dataset = dataset.map(lambda x: x * 2) # x is a batch, can speed things up by setting num_parallel_calls argument to number of threads to run or to tf.data.AUTOTUNE.\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efa7aec1-474a-4196-a13b-1908abdc23d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# filter batches whose sum is less than or equal to 50\n",
    "dataset = dataset.filter(lambda x: tf.reduce_sum(x) > 50)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07c14629-4507-43f8-b60e-b0cadbdc2309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# look at first n items in dataset \n",
    "for item in dataset.take(2):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0643140-e2f4-4448-bc67-ee51cabe68d6",
   "metadata": {},
   "source": [
    "### Shuffling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6046973-f2f3-497a-9434-0ab8b88e14bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 4 2 3 5 0 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([9 8 2 0 3 1 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 7 9 6 7 8], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10).repeat(2)\n",
    "dataset = dataset.shuffle(buffer_size=4, seed=42).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d34b8-ec35-4dbd-86e8-4904f0d73d0b",
   "metadata": {},
   "source": [
    "### Interleaving Lines from Multiple Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0277bae0-194e-4d23-8ba0-cdf4f1010890",
   "metadata": {},
   "source": [
    "_suppose we have many csv files for the train set and all their paths are store in an array called train_filepaths_\n",
    "\n",
    "train_filepaths = [\"path1.csv\", \"path2.csv\", \"path3.csv\", ...] or just \"path*.csv\"\n",
    "\n",
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e86b54-ac71-4009-bee3-e401edf69bb0",
   "metadata": {},
   "source": [
    "_next, call the interleave() method to read from 5 files at a time and interleave their lines_\n",
    "\n",
    "n_reader = 5\n",
    "\n",
    "dataset = filepath_dataset.interleave(\n",
    "lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "cycle_length=n_readers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9c4915-6159-4991-b4fd-9903ffc1b43d",
   "metadata": {},
   "source": [
    "Can use interleave's num_parallel_call to use more threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de644369-1634-4c6c-8c0f-8263c77e7bd6",
   "metadata": {},
   "source": [
    "### Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b13a3cc-0205-4bbf-b603-fb1b62ee3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c46f5493-afc2-4c74-989c-89da765748ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the california housing dataset\n",
    "n_inputs = 8\n",
    "X_mean, X_std = [np.array([.5] * n_inputs), np.array([2.] * n_inputs)]\n",
    "\n",
    "def parse_csv_line(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    return tf.stack(fields[:-1]), tf.stack(fields[-1:])\n",
    "\n",
    "def preprocess(line):\n",
    "    x, y = parse_csv_line(line)\n",
    "    return (x - X_mean) / X_std, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5c8eb13-0fe4-4f8b-bfcb-6174fbb2e47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([ 1.8541501e+00,  2.1750000e+01,  2.4116001e+00,  2.0855001e-01,\n",
       "         4.2275000e+02,  9.1849995e-01,  1.8485001e+01, -6.1349998e+01],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a79145-1ba7-45c7-a1eb-c713f764e643",
   "metadata": {},
   "source": [
    "Use dataset's map() method to apply the preprocess() function to each sample in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79823e15-92a6-4fcd-90e8-8de8a5ee0969",
   "metadata": {},
   "source": [
    "### Putting Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea5b7033-b66e-4d32-a691-ba63ac5249e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, n_readers=5, n_read_threads=None,\n",
    "                       n_parse_threads=5, shuffle_buffer_size=10_000, seed=42,\n",
    "                       batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths, seed=seed)\n",
    "    \n",
    "    dataset = dataset.interleave(\n",
    "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "    cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    \n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size, seed=seed)\n",
    "    \n",
    "    return dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82372e8-77f7-474e-ac4f-008b772b7e61",
   "metadata": {},
   "source": [
    "### Using the Dataset with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d399692f-b6d6-45c2-bacf-1edcc4ff4a22",
   "metadata": {},
   "source": [
    "train_set = csv_reader_dataset(train_filepaths)\n",
    "\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "\n",
    "test_set = csv_reader_dataset(test_filepaths)\n",
    "\n",
    "model = tf.keras.Sequential([...])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "\n",
    "model.fit(train_set, validation_data=valid_set, epochs=5)\n",
    "\n",
    "test_mse = model.evaluate(test_set)\n",
    "\n",
    "new_set = test_set.take(3) # pretend we have 3 new samples\n",
    "\n",
    "y_pred = model.predict(new_set) # or you could just pass a NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0be389-abec-41b4-bebe-da437e6eb2d4",
   "metadata": {},
   "source": [
    "_If you want to build a custom training loop:_\n",
    "\n",
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for X_batch, y_batch in train_set:\n",
    "        [...] # perform one gradient descent step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1b99c29-1ce4-479b-b30d-a1e324e8c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can even create a TF function that trains the model for a whole epoch:\n",
    "@tf.function\n",
    "def train_one_epoch(model, optimizer, loss_fn, train_set):\n",
    "    for X_batch, y_batch in train_set:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main__loss] + model.losses)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "# loss_fn = tf.keras.losses.MeanSquaredError\n",
    "# for epoch in range(n_epochs):\n",
    "#     print(\"\\rEpoch {}/{}\".format(epoch + 1, n_epochs), end=\"\")\n",
    "#     traine_one_epoch(model, optimzier, loss_fn, train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecdfbbd-f38c-43b2-8795-418df9bb6db1",
   "metadata": {},
   "source": [
    "In Keras, the _steps_per_execution_ argument of the compile() method lets you define the number of batches that the fit() method will process during each call to the tf.function it uses for training. The default is just 1, so if you set it ot 50 you will often see a significant performance improvement. However, the on_batch_*() methods of Keras callbacks will only be called every 50 batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb94436-626f-4218-b873-e587facd960b",
   "metadata": {},
   "source": [
    "## The TFRecord Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b340d390-53ca-41b1-8241-fc876e909dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89bd4de0-7b26-4e9a-a114-c82a79299188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
      "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "filepaths = [\"my_data.tfrecord\"]\n",
    "dataset = tf.data.TFRecordDataset(filepaths)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9df552-5e8d-408f-a70a-e33fda7b8a4b",
   "metadata": {},
   "source": [
    "By default, a TFRecordDataset will read files one by one, but you make it read multiple files in parallel and interleave their records by passing the constructor a list of filepaths and setting num_parallel_reads to a number greater than one. Alternatively, you could obtain the same result by using list_files() and interleave() as we did earlier to read multiple CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d408d8c9-0b6c-41d7-abb2-9bb3fead6c09",
   "metadata": {},
   "source": [
    "### Compresssed TFRecord Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e617b3ab-9dcc-4767-be2d-1f3df7c59d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compress\n",
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
    "    f.write(\"Compress, compress, compress!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecaa7670-07ac-4793-b906-a1af998fe5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Compress, compress, compress!', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# decompress\n",
    "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"],\n",
    "                                 compression_type=\"GZIP\")\n",
    "\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dfc365-1ce6-48a7-8216-24f71e5472f2",
   "metadata": {},
   "source": [
    "### A Brief Introduction to Protocol Buffers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c10f056-4919-4e8d-856f-c2d0ff27d453",
   "metadata": {},
   "source": [
    "see page 454"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf2884f-79b9-42f7-812b-7efe45177fd8",
   "metadata": {},
   "source": [
    "### TensorFlow Protobufs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ad545eb-8146-484a-999b-2285fe2ae62a",
   "metadata": {},
   "source": [
    "syntax = \"proto3\";\n",
    "message BytesList { repeated bytes value = 1; }\n",
    "message FloatList { repeated float value = 1 [packed = true]; }\n",
    "message Int64List { repeated float value = 1 [packed = true]; }\n",
    "message Feature {\n",
    "    oneof kind {\n",
    "        BytesList bytes_list = 1;\n",
    "        FloatList float_list = 2;\n",
    "        Int64List int64_list = 3;\n",
    "    }\n",
    "};\n",
    "message Features { map<string, Feature> feature = 1;};\n",
    "message Example { Features features = 1; };"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfe2d811-ad4c-4d67-bafa-3cf0b27c6812",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create a tf.train.Example representing a person\n",
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Feature, Features, Example\n",
    "\n",
    "person_example = Example(\n",
    "    features=Features(\n",
    "        feature={\n",
    "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
    "            \"id\": Feature(int64_list=Int64List(value=[123])),\n",
    "            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\",\n",
    "                                                          b\"c@d.com\"]))\n",
    "        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d55e280c-1660-4de8-a4bf-f089e7c00cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
    "    for _ in range(5):\n",
    "        f.write(person_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc27651-d2a3-4c2c-b5bc-bf7b84894695",
   "metadata": {},
   "source": [
    "### Loading and Parsing Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985da771-f510-4c71-a971-537f80bbbb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    \"name\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "    \"id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"emails\": tf.io.VarLenFeature(tf.string),\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
