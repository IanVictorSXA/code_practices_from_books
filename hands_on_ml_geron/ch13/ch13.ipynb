{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e4ed82-3bf5-47c4-bce0-2592429eb480",
   "metadata": {},
   "source": [
    "# **Chapter 13 â€“ Loading and Preprocessing Data with TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78770d3-2b05-4fd7-b4f8-43f5ab8ea645",
   "metadata": {},
   "source": [
    "# The tf.data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20020016-d802-4cb4-9f78-b1a371865174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e131e8-2179-43f0-aa39-1ce9b94aed63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(10) # any data tensor\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd9cbe0b-44b2-4ba8-bdea-baa5dad5011f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_RangeDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or \n",
    "tf.data.Dataset.range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4432a1e-4a7b-4cb5-88d0-05fbbbc4875a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# can iterate\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad97793-95c2-4412-b480-c96ecdb90845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=4>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=7>}\n",
      "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=5>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=8>}\n",
      "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=6>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=9>}\n"
     ]
    }
   ],
   "source": [
    "X_nested = {\"a\": ([1, 2, 3], [4, 5, 6]), \"b\": [7, 8, 9]}\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_nested)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb5f51e-1b13-46de-a4ad-cb0d0cfcb4cf",
   "metadata": {},
   "source": [
    "## Chaining Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c901668-d264-4964-865b-ec0fea86654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
    "dataset = dataset.repeat(3).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "881009a2-7634-4088-82c9-c03ef8ad0bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
      "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# tranforming items by calling map()\n",
    "dataset = dataset.map(lambda x: x * 2) # x is a batch, can speed things up by setting num_parallel_calls argument to number of threads to run or to tf.data.AUTOTUNE.\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efa7aec1-474a-4196-a13b-1908abdc23d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# filter batches whose sum is less than or equal to 50\n",
    "dataset = dataset.filter(lambda x: tf.reduce_sum(x) > 50)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07c14629-4507-43f8-b60e-b0cadbdc2309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# look at first n items in dataset \n",
    "for item in dataset.take(2):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0643140-e2f4-4448-bc67-ee51cabe68d6",
   "metadata": {},
   "source": [
    "### Shuffling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6046973-f2f3-497a-9434-0ab8b88e14bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 4 2 3 5 0 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([9 8 2 0 3 1 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 7 9 6 7 8], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10).repeat(2)\n",
    "dataset = dataset.shuffle(buffer_size=4, seed=42).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d34b8-ec35-4dbd-86e8-4904f0d73d0b",
   "metadata": {},
   "source": [
    "### Interleaving Lines from Multiple Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0277bae0-194e-4d23-8ba0-cdf4f1010890",
   "metadata": {},
   "source": [
    "_suppose we have many csv files for the train set and all their paths are store in an array called train_filepaths_\n",
    "\n",
    "train_filepaths = [\"path1.csv\", \"path2.csv\", \"path3.csv\", ...] or just \"path*.csv\"\n",
    "\n",
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e86b54-ac71-4009-bee3-e401edf69bb0",
   "metadata": {},
   "source": [
    "_next, call the interleave() method to read from 5 files at a time and interleave their lines_\n",
    "\n",
    "n_reader = 5\n",
    "\n",
    "dataset = filepath_dataset.interleave(\n",
    "lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "cycle_length=n_readers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9c4915-6159-4991-b4fd-9903ffc1b43d",
   "metadata": {},
   "source": [
    "Can use interleave's num_parallel_call to use more threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de644369-1634-4c6c-8c0f-8263c77e7bd6",
   "metadata": {},
   "source": [
    "### Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b13a3cc-0205-4bbf-b603-fb1b62ee3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c46f5493-afc2-4c74-989c-89da765748ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the california housing dataset\n",
    "n_inputs = 8\n",
    "X_mean, X_std = [np.array([.5] * n_inputs), np.array([2.] * n_inputs)]\n",
    "\n",
    "def parse_csv_line(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    return tf.stack(fields[:-1]), tf.stack(fields[-1:])\n",
    "\n",
    "def preprocess(line):\n",
    "    x, y = parse_csv_line(line)\n",
    "    return (x - X_mean) / X_std, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5c8eb13-0fe4-4f8b-bfcb-6174fbb2e47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([ 1.8541501e+00,  2.1750000e+01,  2.4116001e+00,  2.0855001e-01,\n",
       "         4.2275000e+02,  9.1849995e-01,  1.8485001e+01, -6.1349998e+01],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a79145-1ba7-45c7-a1eb-c713f764e643",
   "metadata": {},
   "source": [
    "Use dataset's map() method to apply the preprocess() function to each sample in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79823e15-92a6-4fcd-90e8-8de8a5ee0969",
   "metadata": {},
   "source": [
    "### Putting Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea5b7033-b66e-4d32-a691-ba63ac5249e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, n_readers=5, n_read_threads=None,\n",
    "                       n_parse_threads=5, shuffle_buffer_size=10_000, seed=42,\n",
    "                       batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths, seed=seed)\n",
    "    \n",
    "    dataset = dataset.interleave(\n",
    "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "    cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    \n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size, seed=seed)\n",
    "    \n",
    "    return dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82372e8-77f7-474e-ac4f-008b772b7e61",
   "metadata": {},
   "source": [
    "### Using the Dataset with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d399692f-b6d6-45c2-bacf-1edcc4ff4a22",
   "metadata": {},
   "source": [
    "train_set = csv_reader_dataset(train_filepaths)\n",
    "\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "\n",
    "test_set = csv_reader_dataset(test_filepaths)\n",
    "\n",
    "model = tf.keras.Sequential([...])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "\n",
    "model.fit(train_set, validation_data=valid_set, epochs=5)\n",
    "\n",
    "test_mse = model.evaluate(test_set)\n",
    "\n",
    "new_set = test_set.take(3) # pretend we have 3 new samples\n",
    "\n",
    "y_pred = model.predict(new_set) # or you could just pass a NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0be389-abec-41b4-bebe-da437e6eb2d4",
   "metadata": {},
   "source": [
    "_If you want to build a custom training loop:_\n",
    "\n",
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for X_batch, y_batch in train_set:\n",
    "        [...] # perform one gradient descent step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1b99c29-1ce4-479b-b30d-a1e324e8c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can even create a TF function that trains the model for a whole epoch:\n",
    "@tf.function\n",
    "def train_one_epoch(model, optimizer, loss_fn, train_set):\n",
    "    for X_batch, y_batch in train_set:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main__loss] + model.losses)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "# loss_fn = tf.keras.losses.MeanSquaredError\n",
    "# for epoch in range(n_epochs):\n",
    "#     print(\"\\rEpoch {}/{}\".format(epoch + 1, n_epochs), end=\"\")\n",
    "#     traine_one_epoch(model, optimzier, loss_fn, train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecdfbbd-f38c-43b2-8795-418df9bb6db1",
   "metadata": {},
   "source": [
    "In Keras, the _steps_per_execution_ argument of the compile() method lets you define the number of batches that the fit() method will process during each call to the tf.function it uses for training. The default is just 1, so if you set it ot 50 you will often see a significant performance improvement. However, the on_batch_*() methods of Keras callbacks will only be called every 50 batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb94436-626f-4218-b873-e587facd960b",
   "metadata": {},
   "source": [
    "## The TFRecord Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b340d390-53ca-41b1-8241-fc876e909dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89bd4de0-7b26-4e9a-a114-c82a79299188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
      "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "filepaths = [\"my_data.tfrecord\"]\n",
    "dataset = tf.data.TFRecordDataset(filepaths)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9df552-5e8d-408f-a70a-e33fda7b8a4b",
   "metadata": {},
   "source": [
    "By default, a TFRecordDataset will read files one by one, but you make it read multiple files in parallel and interleave their records by passing the constructor a list of filepaths and setting num_parallel_reads to a number greater than one. Alternatively, you could obtain the same result by using list_files() and interleave() as we did earlier to read multiple CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d408d8c9-0b6c-41d7-abb2-9bb3fead6c09",
   "metadata": {},
   "source": [
    "### Compresssed TFRecord Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e617b3ab-9dcc-4767-be2d-1f3df7c59d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compress\n",
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
    "    f.write(\"Compress, compress, compress!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecaa7670-07ac-4793-b906-a1af998fe5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Compress, compress, compress!', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# decompress\n",
    "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"],\n",
    "                                 compression_type=\"GZIP\")\n",
    "\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dfc365-1ce6-48a7-8216-24f71e5472f2",
   "metadata": {},
   "source": [
    "### A Brief Introduction to Protocol Buffers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c10f056-4919-4e8d-856f-c2d0ff27d453",
   "metadata": {},
   "source": [
    "see page 454"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf2884f-79b9-42f7-812b-7efe45177fd8",
   "metadata": {},
   "source": [
    "### TensorFlow Protobufs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ad545eb-8146-484a-999b-2285fe2ae62a",
   "metadata": {},
   "source": [
    "syntax = \"proto3\";\n",
    "message BytesList { repeated bytes value = 1; }\n",
    "message FloatList { repeated float value = 1 [packed = true]; }\n",
    "message Int64List { repeated float value = 1 [packed = true]; }\n",
    "message Feature {\n",
    "    oneof kind {\n",
    "        BytesList bytes_list = 1;\n",
    "        FloatList float_list = 2;\n",
    "        Int64List int64_list = 3;\n",
    "    }\n",
    "};\n",
    "message Features { map<string, Feature> feature = 1;};\n",
    "message Example { Features features = 1; };"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfe2d811-ad4c-4d67-bafa-3cf0b27c6812",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create a tf.train.Example representing a person\n",
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Feature, Features, Example\n",
    "\n",
    "person_example = Example(\n",
    "    features=Features(\n",
    "        feature={\n",
    "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
    "            \"id\": Feature(int64_list=Int64List(value=[123])),\n",
    "            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\",\n",
    "                                                          b\"c@d.com\"]))\n",
    "        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d55e280c-1660-4de8-a4bf-f089e7c00cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
    "    for _ in range(5):\n",
    "        f.write(person_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc27651-d2a3-4c2c-b5bc-bf7b84894695",
   "metadata": {},
   "source": [
    "### Loading and Parsing Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "985da771-f510-4c71-a971-537f80bbbb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emails': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d.com'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64)), 'id': <tf.Tensor: shape=(), dtype=int64, numpy=123>, 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Alice'>}\n",
      "{'emails': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d.com'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64)), 'id': <tf.Tensor: shape=(), dtype=int64, numpy=123>, 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Alice'>}\n",
      "{'emails': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d.com'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64)), 'id': <tf.Tensor: shape=(), dtype=int64, numpy=123>, 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Alice'>}\n",
      "{'emails': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d.com'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64)), 'id': <tf.Tensor: shape=(), dtype=int64, numpy=123>, 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Alice'>}\n",
      "{'emails': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d.com'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64)), 'id': <tf.Tensor: shape=(), dtype=int64, numpy=123>, 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Alice'>}\n"
     ]
    }
   ],
   "source": [
    "feature_description = {\n",
    "    \"name\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "    \"id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"emails\": tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "\n",
    "def parse(serialized_example):\n",
    "    return tf.io.parse_single_example(serialized_example, feature_description)\n",
    "\n",
    "dataset = tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]).map(parse)\n",
    "for parsed_example in dataset:\n",
    "    print(parsed_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d484cd75-9517-492d-a52e-f3e67c3e8659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variable-length features are parsed as sparse tensors. Can convert to a dense tensor using tf.sparse.to_dense()\n",
    "tf.sparse.to_dense(parsed_example[\"emails\"], default_value=b\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cc4009e-8252-41f3-98fc-c62bc36add44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but in this case it is simpler to just access its values:\n",
    "parsed_example[\"emails\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43778dda-c513-4626-9d38-7b980f8e2cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emails': SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]], shape=(4, 2), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d.com' b'a@b.com' b'c@d.com'], shape=(4,), dtype=string), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64)), 'id': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([123, 123])>, 'name': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'Alice', b'Alice'], dtype=object)>}\n",
      "{'emails': SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]], shape=(4, 2), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d.com' b'a@b.com' b'c@d.com'], shape=(4,), dtype=string), dense_shape=tf.Tensor([2 2], shape=(2,), dtype=int64)), 'id': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([123, 123])>, 'name': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'Alice', b'Alice'], dtype=object)>}\n",
      "{'emails': SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d.com'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64)), 'id': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([123])>, 'name': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Alice'], dtype=object)>}\n"
     ]
    }
   ],
   "source": [
    "# can parse examples batch by batch using tf.io.parse_example():\n",
    "def parse(serialized_examples):\n",
    "    return tf.io.parse_example(serialized_examples, feature_description)\n",
    "\n",
    "dataset = tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]).batch(2).map(parse)\n",
    "for parsed_examples in dataset:\n",
    "    print(parsed_examples) # two examples at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1a2392-4554-4bf8-a84b-b7c727301e6f",
   "metadata": {},
   "source": [
    "See page 458 about storing images and tf.tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb38c2e6-fa7b-4e37-aba6-c64e2c8fbe17",
   "metadata": {},
   "source": [
    "### Handling Lists of Lists Using the SequenceExample Protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a5c88d-2c6a-4047-a9f5-de17a9e1b7e0",
   "metadata": {},
   "source": [
    "If features lists contain sequences of varying sizes, you may want to convert them to ragged tensors using tf.RaggedTensor.from_sparse() (see page 459)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ee2bf49-2bb0-409e-8cb9-cf975a2ab9df",
   "metadata": {},
   "source": [
    "parsed_context, parsed_feature_lists = tf.io.parse_single_sequence_example(\n",
    "    serialized_sequence_example, context_feature_descriptions,\n",
    "    sequence_feature_descriptions)\n",
    "parsed_content = tf.RaggedTensor.from_sparse(parsed_feature_lists[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8e62e-1b08-4ce1-8f41-4bfb768345cc",
   "metadata": {},
   "source": [
    "### Normalization Layer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80516ac0-f129-4df0-8faf-67fd67b20001",
   "metadata": {},
   "source": [
    "norm_layer = tf.keras.layers.Normalization()\n",
    "model = tf.keras.models.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=2e-3))\n",
    "norm_layer.adapt(X_train) # computes the mean and variance of every feature\n",
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91401f3e-2a91-42a7-9499-290196f64faa",
   "metadata": {},
   "source": [
    "# Faster training if we normalize dataset first and not include preprocessing layer in the model until training is complete\n",
    "norm_layer = tf.keras.layers.Normalization()\n",
    "norm_layer.adapt(X_train)\n",
    "X_train_scaled = norm_layer(X_train)\n",
    "X_valid_scaled = norm_layer(X_valid)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65bab736-e800-4511-8766-3691362f43c6",
   "metadata": {},
   "source": [
    "# train without a a Normalization layer\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Dense(1)])\n",
    "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=2e-3))\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d416c455-84f5-4bb9-b3f6-6299ae3ce39b",
   "metadata": {},
   "source": [
    "# When deploying model to production, we just need to create a new model that wraps both the adapted Normalization layer and the model we just trained\n",
    "final_model = tf.keras.Sequential([norm_layer, model])\n",
    "X_new = X_test[:3] # pretend we have few new instnces (unscaled)\n",
    "y_pred = final_model(X_new) # preprocess the data and makes predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fd592f-934d-499b-83d3-fb8faedc251d",
   "metadata": {},
   "source": [
    "It is possible to pass a tf.data.Dataset to a preprocessing layer's adapt() method. It is also possible to apply a Keras preprocessing layer to a tf.data.Dataset using the dataset's map() method. Here is how you can could apply an adapted Normalization layer to the input features of each batch in a dataset:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7a1e8c4-976d-499b-b5ad-8e207a1be550",
   "metadata": {},
   "source": [
    "dataset = dataset.map(lambda X, y: (norm_layer(X), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e41675-7788-492d-bb74-e607089ac3e1",
   "metadata": {},
   "source": [
    "### The discretezation layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70724dc3-a733-495c-9d88-02d2169d85e1",
   "metadata": {},
   "source": [
    "3 categories: less than 18, 18 to 50 (not included), and 50 or over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69042b67-10f5-45d2-9ec6-50d49ed1084e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 1), dtype=int32, numpy=\n",
       "array([[0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = tf.constant([[10.], [93.], [57.], [18.], [37.], [5.]])\n",
    "discretize_layer = tf.keras.layers.Discretization(bin_boundaries=[18., 50.])\n",
    "age_categories = discretize_layer(age)\n",
    "age_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a18371-0bf9-416d-a8e2-c8de1ebefb91",
   "metadata": {},
   "source": [
    "We can instead provide the number of bins you want, then call the layer's adapt() method to let it find the appropriate bin boundaries based on the value percentiles. For example, if we set num_bins=3, then the bind boundaries will be located at the values just bellow the 33rd and 66th percentiles (in this example, at the values 10 and 37):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8278fb63-8767-4648-bb3b-5140fe893869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 1), dtype=int32, numpy=\n",
       "array([[1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0]], dtype=int32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretize_layer = tf.keras.layers.Discretization(num_bins=3)\n",
    "discretize_layer.adapt(age)\n",
    "age_categories = discretize_layer(age)\n",
    "age_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e2302-ef97-43af-aa05-487a893f0cc0",
   "metadata": {},
   "source": [
    "### The CategoryEncoding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d18d58db-35d8-431f-9798-5203cc3156d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_layer = tf.keras.layers.CategoryEncoding(num_tokens=3)\n",
    "onehot_layer(age_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48238451-762e-4859-8d52-8474bbab9ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multi-hot encoding:\n",
    "two_age_categories = np.array([[1, 0], [2, 2], [2, 0]])\n",
    "onehot_layer(two_age_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf849e99-5342-45ea-ad62-805a27c38145",
   "metadata": {},
   "source": [
    "if you want to count how mnay times each category occurred, set output_mode=\"count\", when creating the layer. The output would be the same except for the second row above, which would become [0, 0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b967295-f248-4170-bf8a-c7b175e65729",
   "metadata": {},
   "source": [
    "both multi-hot encoding and count encoding lose information, since it is not possible to know which feature each active category came from. If you want to avoid this, then you need to one-hot encode each feature separately and concatenate the outputs. You can get the same result by tweaking the category identifiers so they don't overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91c58c80-2fef-4207-ae32-dd6519113fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 6), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 1., 1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_layer = tf.keras.layers.CategoryEncoding(num_tokens=3 + 3)\n",
    "onehot_layer(two_age_categories + [0, 3]) # adds 3 to the second feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8e482-5cb1-4a95-adf9-122dfda1d27b",
   "metadata": {},
   "source": [
    "In this output, the first 3 columns corresponde to the first feature, and the last three correspond to the second feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a142f95e-5ed3-4207-a7ef-799a0f6ebe23",
   "metadata": {},
   "source": [
    "### The StringLookup Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c2ce853-d1fa-4876-8e66-414056397779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=int64, numpy=\n",
       "array([[1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0]])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encode a cities feature:\n",
    "cities = [\"Auckland\", \"Paris\", \"Paris\", \"San Francisco\"]\n",
    "str_lookup_layer = tf.keras.layers.StringLookup()\n",
    "str_lookup_layer.adapt(cities)\n",
    "str_lookup_layer([[\"Paris\"], [\"Auckland\"], [\"Auckland\"], [\"Montreal\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c3e185d-99b8-4c0a-bb12-9332eb076f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=int64, numpy=\n",
       "array([[0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 0]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using output_mode=\"one_hot\"\n",
    "str_lookup_layer = tf.keras.layers.StringLookup(output_mode=\"one_hot\")\n",
    "str_lookup_layer.adapt(cities)\n",
    "str_lookup_layer([[\"Paris\"], [\"Auckland\"], [\"Auckland\"], [\"Montreal\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d67590d-e16d-4dea-a69e-6b86baf83d59",
   "metadata": {},
   "source": [
    "Keras also includes IntegerLookup layer which is just like StringLookup but for integers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06802bc-bc0e-4205-a8d9-5b97ffe30476",
   "metadata": {},
   "source": [
    "If the training set is large, it may be convenient to adapt the layer to just a random subste of the training set. In this case, the layer's adapt() method may miss some of the rarer categories. By default, it would then map them all to category 0, making them indistinguishable. To reduce this risk, you can set num_oov_indies to an integer greater than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfb9be58-4145-4365-ad81-705bd067ef81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
       "array([[5],\n",
       "       [7],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_lookup_layer = tf.keras.layers.StringLookup(num_oov_indices=5)\n",
    "str_lookup_layer.adapt(cities)\n",
    "str_lookup_layer([[\"Paris\"], [\"Auckland\"], [\"Foo\"], [\"Bar\"], [\"Baz\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869cdf5e-e71a-434e-8630-136aade83426",
   "metadata": {},
   "source": [
    "### The Hashing Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9bf00476-26d8-4848-a0e8-398a86fbaa24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=int64, numpy=\n",
       "array([[0],\n",
       "       [1],\n",
       "       [9],\n",
       "       [1]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashing_layer = tf.keras.layers.Hashing(num_bins=10)\n",
    "hashing_layer([[\"Paris\"], [\"Tokyo\"], [\"Auckland\"], [\"Montreal\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066413ba-2ed5-4522-9873-fbef118854f8",
   "metadata": {},
   "source": [
    "The benefit of this layer is that it does not need to be adapted at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444d8948-b9b9-4d9a-b341-28d4e662c2a9",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features Using Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537324c-60dc-4cba-aae4-91cbe30e9fd9",
   "metadata": {},
   "source": [
    "Initialize an embedding layer with five rows and 2d embeddings, and use it to encode some categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69d21c3c-8cdd-4fed-8347-8d99d0784b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[-0.00498476,  0.0461193 ],\n",
       "       [ 0.04001949,  0.03139852],\n",
       "       [-0.00498476,  0.0461193 ]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=5, output_dim=2)\n",
    "embedding_layer(np.array([2, 4, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f441e4d-1541-4ca2-a2a1-405c78bc49c1",
   "metadata": {},
   "source": [
    "If you want to embed a categorical text attribute, you can simply chain a String Lookup layer and an Embedding layer, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c086e53e-bf75-4ad6-80a9-dd71b182b3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 2), dtype=float32, numpy=\n",
       "array([[[0.00639011, 0.01911124]],\n",
       "\n",
       "       [[0.00778233, 0.00470138]],\n",
       "\n",
       "       [[0.00639011, 0.01911124]]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "ocean_prox = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
    "str_lookup_layer = tf.keras.layers.StringLookup()\n",
    "str_lookup_layer.adapt(ocean_prox)\n",
    "lookup_and_embed = tf.keras.Sequential([\n",
    "    str_lookup_layer,\n",
    "    tf.keras.layers.Embedding(input_dim=str_lookup_layer.vocabulary_size(),\n",
    "                              output_dim=2)\n",
    "])\n",
    "\n",
    "lookup_and_embed(np.array([[\"<1H OCEAN\"], [\"ISLAND\"], [\"<1H OCEAN\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1849fb38-d52c-4bdd-ad61-02294120eaa2",
   "metadata": {},
   "source": [
    "Putting everything together, we can now create a Keras model that can process a categorical text feature along with regular numerical features and learn and learn an embedding for each category:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d7303ab-0b70-44c9-b4b8-4d2982bfaee4",
   "metadata": {},
   "source": [
    "X_train_num, X_train_cat, y_train = [...] # load the training set\n",
    "X_valid_num, X_valid_cat, y_valid = [...] # and the validation set\n",
    "\n",
    "num_input = tf.keras.layers.Input(shape=[8], name=\"num\")\n",
    "cat_input = tf.keras.layers.Input(shape=[], dtype=tf.string, name=\"cat\")\n",
    "cat_embeddings = lookup_and_embed(cat_input)\n",
    "encoded_inputs = tf.keras.layers.concatenate([num_input, cat_embeddings])\n",
    "outputs = tf.keras.layers.Dense(1)(encoded_inputs)\n",
    "model = tf.keras.models.Model(inputs=[num_input, cat_input], outputs=[outputs])\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "history = model.fit((X_train_num, X_train_cat), y_train, epochs=5,\n",
    "                    validation_data=((X_valid_num, X_valid_cat), y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee04648c-4c91-4065-a7c3-3994974397c1",
   "metadata": {},
   "source": [
    "We could also have passed the training data to the fit() method using a dictionary instead of a tuple: {\"num\": X_train_num, \"cat\": X_train_cat}. Alternatively, we could have passed a tf.data.Dataset containing batches, each represenetd as ((X_batch_num, X_batch_cat), y_batch) or as ({\"num\": X_batch_num, \"cat\": X_batch_cat}, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0b6a5c-a15c-43ca-9d7c-3794b6c4356c",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "635783ec-2e74-41b6-ba58-8db8e2fa8f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=int64, numpy=\n",
       "array([[2, 1, 0, 0],\n",
       "       [6, 2, 1, 2]])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = [\"To be\", \"!(to be)\", \"That's the question\", \"Be, be, be.\"]\n",
    "text_vec_layer = tf.keras.layers.TextVectorization()\n",
    "text_vec_layer.adapt(train_data)\n",
    "text_vec_layer([\"Be good!\", \"Question: be or be?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57e5ab9c-8464-4d78-9aab-c6e91b0e4060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\n",
       "array([[0.96725637, 0.6931472 , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.96725637, 1.3862944 , 0.        , 0.        , 0.        ,\n",
       "        1.0986123 ]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting output_mode to TF-IDF\n",
    "text_vec_layer = tf.keras.layers.TextVectorization(output_mode=\"tf_idf\")\n",
    "text_vec_layer.adapt(train_data)\n",
    "text_vec_layer([\"Be good!\", \"Question: be or be?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c0e9d-25e6-41ea-abfe-fdedf63291cb",
   "metadata": {},
   "source": [
    "### Using Pretrained Language Model Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc04a481-89e3-4784-9f85-720ceeac609e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ianvi\\env311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ianvi\\env311\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ianvi\\env311\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ianvi\\env311\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ianvi\\env311\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ianvi\\env311\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ianvi\\env311\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.25,  0.28,  0.01,  0.1 ,  0.14,  0.16,  0.25,  0.02,  0.07,\n",
       "         0.13, -0.19,  0.06, -0.04, -0.07,  0.  , -0.08, -0.14, -0.16,\n",
       "         0.02, -0.24,  0.16, -0.16, -0.03,  0.03, -0.14,  0.03, -0.09,\n",
       "        -0.04, -0.14, -0.19,  0.07,  0.15,  0.18, -0.23, -0.07, -0.08,\n",
       "         0.01, -0.01,  0.09,  0.14, -0.03,  0.03,  0.08,  0.1 , -0.01,\n",
       "        -0.03, -0.07, -0.1 ,  0.05,  0.31],\n",
       "       [-0.2 ,  0.2 , -0.08,  0.02,  0.19,  0.05,  0.22, -0.09,  0.02,\n",
       "         0.19, -0.02, -0.14, -0.2 , -0.04,  0.01, -0.07, -0.22, -0.1 ,\n",
       "         0.16, -0.44,  0.31, -0.1 ,  0.23,  0.15, -0.05,  0.15, -0.13,\n",
       "        -0.04, -0.08, -0.16, -0.1 ,  0.13,  0.13, -0.18, -0.04,  0.03,\n",
       "        -0.1 , -0.07,  0.07,  0.03, -0.08,  0.02,  0.05,  0.07, -0.14,\n",
       "        -0.1 , -0.18, -0.13, -0.04,  0.15]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "hub_layer = hub.KerasLayer(\"https://www.kaggle.com/models/google/nnlm/TensorFlow2/en-dim50/1\")\n",
    "\n",
    "sentence_embeddings = hub_layer(tf.constant([\"To be\", \"Not to be\"]))\n",
    "sentence_embeddings.numpy().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7103b31-313d-4117-ae06-f30db4751300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 50)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651af57-d305-47e6-8c84-f309df5353a2",
   "metadata": {},
   "source": [
    "### Image Preprocessing Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7c8a6c-0474-4c09-a611-0d63a2d40160",
   "metadata": {},
   "source": [
    "It includes 3 preprocessing layers:\n",
    "\n",
    "* tf.keras.layers.Resizing\n",
    "* tf.keras.layers.Rescaling\n",
    "* tf.keras.layers.CenterCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cf3281d-e854-4f41-87c2-06be26c8ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_images\n",
    "\n",
    "images = load_sample_images()[\"images\"]\n",
    "crop_images_layer = tf.keras.layers.CenterCrop(height=100, width=100)\n",
    "cropped_images = crop_images_layer(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff4a25d-28b2-464b-8ecb-8a629695f3a6",
   "metadata": {},
   "source": [
    "Keras also includes several layers for data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4978a-ebb3-4042-9fd3-c80596814d4f",
   "metadata": {},
   "source": [
    "## The TensorFlow Datasets Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76356524-5982-4697-9460-caf943313ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = datasets[\"train\"], datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a42076d5-6d8c-4d2d-b250-9b846a8d1f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in mnist_train.shuffle(10_000, seed=42).batch(32).prefetch(1):\n",
    "    images = batch[\"image\"]\n",
    "    labels = batch[\"label\"]\n",
    "    # [...] do something with the images and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75391bd-51c6-44e4-997d-f88d4e9c202d",
   "metadata": {},
   "source": [
    "Note that each item in the datset is a dictionary containing both the features and the labels. But Keras expects each item to be a tuple containing two elements(again, the features and the labels). You could transform the dataset using the map() method like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "947fa602-2b72-4acb-b93c-44d3e0ca6845",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = mnist_train.shuffle(buffer_size=10_000, seed=42).batch(32)\n",
    "mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
    "mnist_train = mnist_train.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1cb92e-b77d-4c45-b36d-e89d09d94f24",
   "metadata": {},
   "source": [
    "But it is simpler to ask the load() function to do this for you by setting as_supervised=True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247f9fdb-d0be-40c1-9ba7-2a7e096e7988",
   "metadata": {},
   "source": [
    "Can split dataset using split parameter: split=[\"train[:90%]\", \"train[90%:]\", \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fcb1a93e-04c8-48ef-a739-aab1967199ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8356 - loss: 10.1244 - val_accuracy: 0.8730 - val_loss: 6.6363\n",
      "Epoch 2/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8783 - loss: 5.7680 - val_accuracy: 0.8670 - val_loss: 6.1885\n",
      "Epoch 3/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 5.2739 - val_accuracy: 0.8782 - val_loss: 5.9981\n",
      "Epoch 4/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8854 - loss: 5.1385 - val_accuracy: 0.8935 - val_loss: 5.5771\n",
      "Epoch 5/5\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 4.9490 - val_accuracy: 0.8853 - val_loss: 5.9133\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8889 - loss: 5.5199\n"
     ]
    }
   ],
   "source": [
    "# Complete example:\n",
    "train_set, valid_set, test_set = tfds.load(\n",
    "    name=\"mnist\",\n",
    "    split=[\"train[:90%]\", \"train[90%:]\", \"test\"],\n",
    "    as_supervised=True)\n",
    "\n",
    "train_set = train_set.shuffle(buffer_size=10_000, seed=42).batch(32).prefetch(1)\n",
    "valid_set = valid_set.batch(32).cache()\n",
    "test_set = test_set.batch(32).cache()\n",
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input([28, 28]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=5)\n",
    "test_loss, test_accuracy = model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56663fcb-eb0c-428e-8716-efdf65251f6b",
   "metadata": {},
   "source": [
    "# Open-ended questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a505a-be3c-49b7-a4d5-4a489ab8ee23",
   "metadata": {},
   "source": [
    "1. Because it can efficiently load data on the fly or too big to fit on memory, and it can do preprocessing\n",
    "2. Better shuffling\n",
    "3. Time to start training is long. We could do prefetching and store data in a more efficient format.\n",
    "4. Yes, we can save any binary data to TFRecord file, but TF's prefered one is protobufs.\n",
    "5. The Example protobuf is already compiled in TensorFlow. To use our out protobuf definition, we would have to write it and compile it ourselves.\n",
    "6. We would activate compression when we need to send the data over the internet. I believe it would slowdown training.\n",
    "7. Preprocess data when writing the file: it makes training faster, but we would not have the preprocessing parameters when deploying the model for production. Within the tf.data pipeline: slower training as we would do the same computation many times, and we would have to code the preprocessing again for production which is more error-prone. Preprocessing layers within model: slower training, but model would be more portable.\n",
    "8. One-hot encoding, multi-hot encoding, count, one-hot encode features separetely then concatenate. Text: same as numerical, but with TF-IDF, word embeddings, and sentence embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c4ddf8-c731-403b-93c9-c181081d7c6a",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3499084b-33ae-4f36-9aac-e11df0fbb938",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## 1. to 8.\n",
    "1. Ingesting a large dataset and preprocessing it efficiently can be a complex engineering challenge. The Data API makes it fairly simple. It offers many features, including loading data from various sources (such as text or binary files), reading data in parallel from multiple sources, transforming it, interleaving the records, shuffling the data, batching it, and prefetching it.\n",
    "2. Splitting a large dataset into multiple files makes it possible to shuffle it at a coarse level before shuffling it at a finer level using a shuffling buffer. It also makes it possible to handle huge datasets that do not fit on a single machine. It's also simpler to manipulate thousands of small files rather than one huge file; for example, it's easier to split the data into multiple subsets. Lastly, if the data is split across multiple files spread across multiple servers, it is possible to download several files from different servers simultaneously, which improves the bandwidth usage.\n",
    "3. You can use TensorBoard to visualize profiling data: if the GPU is not fully utilized then your input pipeline is likely to be the bottleneck. You can fix it by making sure it reads and preprocesses the data in multiple threads in parallel, and ensuring it prefetches a few batches. If this is insufficient to get your GPU to 100% usage during training, make sure your preprocessing code is optimized. You can also try saving the dataset into multiple TFRecord files, and if necessary perform some of the preprocessing ahead of time so that it does not need to be done on the fly during training (TF Transform can help with this). If necessary, use a machine with more CPU and RAM, and ensure that the GPU bandwidth is large enough.\n",
    "4. A TFRecord file is composed of a sequence of arbitrary binary records: you can store absolutely any binary data you want in each record. However, in practice most TFRecord files contain sequences of serialized protocol buffers. This makes it possible to benefit from the advantages of protocol buffers, such as the fact that they can be read easily across multiple platforms and languages and their definition can be updated later in a backward-compatible way.\n",
    "5. The `Example` protobuf format has the advantage that TensorFlow provides some operations to parse it (the `tf.io.parse`*`example()` functions) without you having to define your own format. It is sufficiently flexible to represent instances in most datasets. However, if it does not cover your use case, you can define your own protocol buffer, compile it using `protoc` (setting the `--descriptor_set_out` and `--include_imports` arguments to export the protobuf descriptor), and use the `tf.io.decode_proto()` function to parse the serialized protobufs (see the \"Custom protobuf\" section of the notebook for an example). It's more complicated, and it requires deploying the descriptor along with the model, but it can be done.\n",
    "6. When using TFRecords, you will generally want to activate compression if the TFRecord files will need to be downloaded by the training script, as compression will make files smaller and thus reduce download time. But if the files are located on the same machine as the training script, it's usually preferable to leave compression off, to avoid wasting CPU for decompression.\n",
    "7. Let's look at the pros and cons of each preprocessing option:\n",
    "    * If you preprocess the data when creating the data files, the training script will run faster, since it will not have to perform preprocessing on the fly. In some cases, the preprocessed data will also be much smaller than the original data, so you can save some space and speed up downloads. It may also be helpful to materialize the preprocessed data, for example to inspect it or archive it. However, this approach has a few cons. First, it's not easy to experiment with various preprocessing logics if you need to generate a preprocessed dataset for each variant. Second, if you want to perform data augmentation, you have to materialize many variants of your dataset, which will use a large amount of disk space and take a lot of time to generate. Lastly, the trained model will expect preprocessed data, so you will have to add preprocessing code in your application before it calls the model. There's a risk of code duplication and preprocessing mismatch in this case.\n",
    "    * If the data is preprocessed with the tf.data pipeline, it's much easier to tweak the preprocessing logic and apply data augmentation. Also, tf.data makes it easy to build highly efficient preprocessing pipelines (e.g., with multithreading and prefetching). However, preprocessing the data this way will slow down training. Moreover, each training instance will be preprocessed once per epoch rather than just once if the data was preprocessed when creating the data files. Well, unless the dataset fits in RAM and you can cache it using the dataset's `cache()` method. Lastly, the trained model will still expect preprocessed data. But if you use preprocessing layers in your tf.data pipeline to handle the preprocessing step, then you can just reuse these layers in your final model (adding them after training), to avoid code duplication and preprocessing mismatch.\n",
    "    * If you add preprocessing layers to your model, you will only have to write the preprocessing code once for both training and inference. If your model needs to be deployed to many different platforms, you will not need to write the preprocessing code multiple times. Plus, you will not run the risk of using the wrong preprocessing logic for your model, since it will be part of the model. On the downside, preprocessing the data on the fly during training will slow things down, and each instance will be preprocessed once per epoch.\n",
    "8. Let's look at how to encode categorical text features and text:\n",
    "    * To encode a categorical feature that has a natural order, such as a movie rating (e.g., \"bad,\" \"average,\" \"good\"), the simplest option is to use ordinal encoding: sort the categories in their natural order and map each category to its rank (e.g., \"bad\" maps to 0, \"average\" maps to 1, and \"good\" maps to 2). However, most categorical features don't have such a natural order. For example, there's no natural order for professions or countries. In this case, you can use one-hot encoding, or embeddings if there are many categories. With Keras, the `StringLookup` layer can be used for ordinal encoding (using the default `output_mode=\"int\"`), or one-hot encoding (using `output_mode=\"one_hot\"`). It can also perform multi-hot encoding (using `output_mode=\"multi_hot\"`) if you want to encode multiple categorical text features together, assuming they share the same categories and it doesn't matter which feature contributed which category. For trainable embeddings, you must first use the `StringLookup` layer to produce an ordinal encoding, then use the `Embedding` layer.\n",
    "    * For text, the `TextVectorization` layer is easy to use and it can work well for simple tasks, or you can use TF Text for more advanced features. However, you'll often want to use pretrained language models, which you can obtain using tools like TF Hub or Hugging Face's Transformers library. These last two options are discussed in Chapter 16."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee7877-a8cb-44e5-9df1-1b2faa13186c",
   "metadata": {},
   "source": [
    "# Coding Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7c0316-05a5-49a1-bc31-f2a5cbe8a7a6",
   "metadata": {},
   "source": [
    "9. Load the Fashion MNIST dataset (introduced in Chapter 10); split it into a training set, a validation set, and a test set; shuffle the training set; and save each dataset to multiple TFRecord files. Each record should be a serialized `Example` protobuf with two features: the serialized image (use `tf.io.serialize_tensor()` to serialize each image), and the label. Note: for large images, you could use `tf.io.encode_jpeg()` instead. This would save a lot of space, but it would lose a bit of image quality. Then use tf.data to create an efficient dataset for each set. Finally, use a Keras model to train these datasets, including a preprocessing layer to standardize each input feature. Try to make the input pipeline as efficient as possible, using TensorBoard to visualize profiling data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "659906cf-98d1-4703-b344-bc9c48d0f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets = tfds.load(\"mnist\", as_supervised=True, split=[\"train[:90%]\", \"train[90%:]\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ba9abfe7-3f4d-4197-8aa1-4432b86dfbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import Features, Feature, Example, BytesList\n",
    "\n",
    "def create_example(X_y):\n",
    "    protobuf_example = Example(\n",
    "        features=Features(\n",
    "            feature={\n",
    "                \"image\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(X_y[0]).numpy()])),\n",
    "                \"target\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(X_y[1]).numpy()]))\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    return protobuf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "57735d2d-ac0b-4281-8bd2-9bfde33cef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "names = (\"train\", \"valid\", \"test\")\n",
    "buffer_sizes = (10_000, 3_000, 5_000)\n",
    "dataset_sizes = (54_000, 6_000, 10_000)\n",
    "rng = np.random.default_rng()\n",
    "number_files = 20\n",
    "files_index = np.arange(number_files)\n",
    "rng.shuffle(files_index)\n",
    "\n",
    "for i, name in enumerate(names):\n",
    "    name_dir = \"mnist_\" + names[i]\n",
    "    os.makedirs(name_dir, exist_ok=True)\n",
    "    dataset = datasets[i].shuffle(buffer_size=buffer_sizes[i])\n",
    "    count = 0\n",
    "    files = [tf.io.TFRecordWriter(os.path.join(name_dir, \"mnist_\" + name + str(j) + \".tfrecord\")) for j in range(number_files)]\n",
    "    \n",
    "    for instance in dataset:\n",
    "        files[files_index[count]].write(create_example(instance).SerializeToString())\n",
    "        count += 1\n",
    "        \n",
    "        if count == number_files:\n",
    "            rng.shuffle(files_index)\n",
    "            count = 0\n",
    "\n",
    "    for file in files:\n",
    "        file.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd27864-d43e-420f-a678-c3ad5027a083",
   "metadata": {},
   "source": [
    "Now load datasets and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ce74431e-d882-4cc2-9fcf-a549f0ccd151",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "    \"target\": tf.io.FixedLenFeature([], tf.string, default_value=\"\")\n",
    "}\n",
    "\n",
    "def parse_batch(serialized_examples):\n",
    "    return tf.io.parse_example(serialized_examples, feature_description)\n",
    "\n",
    "def to_tensor(features_string):\n",
    "    image = tf.io.parse_tensor(features_string[\"image\"], out_type=tf.uint8)\n",
    "    label = tf.io.parse_tensor(features_string[\"target\"], out_type=tf.int64)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3d16330d-8c4c-4a87-ac93-ed0350479f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_datasets = {}\n",
    "for name in names:\n",
    "    files_paths = [os.path.join(\"mnist_\" + name, filename) for filename in os.listdir(\"mnist_\" + name)]\n",
    "    dataset = tf.data.TFRecordDataset(files_paths).batch(32).map(parse_batch).map(to_tensor)\n",
    "    loaded_datasets[name] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2b4a88d9-ad7d-43ac-b8be-cc3cb4531e24",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[169]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m norm_layer = tf.keras.layers.Normalization()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mnorm_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43madapt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\env311\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\normalization.py:228\u001b[39m, in \u001b[36mNormalization.adapt\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    226\u001b[39m     input_shape = data.shape\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, tf.data.Dataset):\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m     input_shape = \u001b[38;5;28mtuple\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43melement_spec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m)\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_shape) == \u001b[32m1\u001b[39m:\n\u001b[32m    230\u001b[39m         \u001b[38;5;66;03m# Batch dataset if it isn't batched\u001b[39;00m\n\u001b[32m    231\u001b[39m         data = data.batch(\u001b[32m128\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "norm_layer = tf.keras.layers.Normalization()\n",
    "norm_layer.adapt(loaded_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "02fdda53-4b64-45d3-a631-3d871b33082e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('train', <TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>), ('valid', <TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>), ('test', <TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>)])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_datasets[\"train\"]  = loaded_datasets[\"train\"].interleave(\n",
    "    \n",
    "\n",
    "loaded_datasets[\"valid\"]  = loaded_datasets[\"valid\"].batch(32).cache()\n",
    "loaded_datasets[\"test\"]  = loaded_datasets[\"test\"].batch(32).cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
